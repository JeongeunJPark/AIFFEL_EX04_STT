{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration 05_ STT        \n",
    "---\n",
    "## 이 노드의 루브릭      \n",
    "1. 음성데이터를 2차원 Spectogram으로 변환하여 데이터셋을 구성하였다.      \n",
    "    -> \"스펙토그램 시각화 및 train/test 데이터셋 구성이 정상 진행되었다.\"    \n",
    "    \n",
    "    \n",
    "2. 1, 2차원 데이터를 처리하는 음성인식 모델이 정상 작동한다.          \n",
    "    -> \"스펙토그램을 입력받은 모델이 학습 과정에서 안정적으로 수렴하며, evaluation/test 단계를 무리없이 진행 가능하다.      \n",
    "    \n",
    "    \n",
    "    \n",
    "3. 테스트셋 수행 결과 음성인식 모델의 Accuracy가 일정 수준에 도달하였다.     \n",
    "    -> \"평가 결과 75% 이상의 정확도를 달성하는 모델이 하나 이상 존재한다.\"    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 목차       \n",
    "\n",
    "1. 데이터 처리와 분류    \n",
    "  - 라벨 데이터 처리하기\n",
    "  - sklearn의 train_test_split 함수를 이용하여 train, test 분리   \n",
    "2. 학습을 위한 하이퍼파라미터 설정     \n",
    "3. 데이터셋 구성        \n",
    "  - tf.data.Dataset을 이용       \n",
    "  - from_tensor_slices에 return 받길 원하는 데이터를 튜플 형태로 받음   \n",
    "  - map과 batch를 사용한 데이터 전처리.\n",
    "  - 메모리 비우기 수행하기    \n",
    "  \n",
    "  > del speech_data\n",
    "  > del spec_data\n",
    "  \n",
    "4. 2차원 Spectogram 데이터를 처리하는 모델 구성     \n",
    "  - 2차원 Spectogram 데이터의 시간축 방향으로 Conv1D/Conv2D 레이어를 적용가능    \n",
    "  - batchnorm, dropout, dense layer 를 이용    \n",
    "  - 12개의 단어 class를 구분하는 loss를 사용하고, Adam optimizer 사용   \n",
    "  - 모델 가중치를 저장하는 checkpoint callback 함수 추가     \n",
    "  \n",
    "5. 학습 내용 그래프 출력\n",
    "  - loss, accuracy를 그래프로 표현     \n",
    "  \n",
    "6. Test dataset을 이용한 모델의 성능 평가   \n",
    "  - 저장한 weight 불러오기    \n",
    "  - 모델의 예측값과 정답값이 얼마나 맞는지 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터 처리와 분류      \n",
    "##### 데이터 가져오기       \n",
    "* 기존에는 Waveform 데이터로 입력받아, Text라벨을 출력하는 모델을 만들었다.    \n",
    "* 이제 이 데이터를 Spectogram으로 입력받아, 동일 역할을 수행하는 모델을 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터를 가져왔다!\n",
      "wav 상태 그대로의 데이터 셰이프 : (50620, 8000)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "data_path = os.getenv(\"HOME\")+'/SUBMIT_MISSION_GIT/ex5_STT/data/speech_wav_8000.npz'\n",
    "speech_data = np.load(data_path)\n",
    "\n",
    "print(\"데이터를 가져왔다!\")\n",
    "print(\"wav 상태 그대로의 데이터 셰이프 :\", speech_data[\"wav_vals\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 내겐 너무 어려웠던 데이터 형변환         \n",
    "* 사실, speech_data -> spectogram data로 형변환하는 과정이 너무 어려웠다.   \n",
    "* 하나하나씩 차근히 분해해보기로 했다.         \n",
    "---\n",
    "1. 일단, speech_data를 이루고 있는 저 npz 확장자는 대체 무엇인지     \n",
    "* npz 파일 포맷은 여러 개의 리스트를 한번에 저장하기 위한 포맷이다.     \n",
    "* 그렇군.      \n",
    "---\n",
    "* 그럼, 얘 안에 들어있는 데이터들은 뭘까?      \n",
    "* 위에서 speech_data를 살펴보았을 때, 데이터는     \n",
    "* speech_data[\"wav_vals\"]와 speech_data[\"label_vals\"]가 있었다.    \n",
    "* wav_vals는 음성 데이터, label_vals는 음성의 뜻을 의미하는 라벨 데이터이다.  \n",
    "* 프린트해서 다시 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "음성 데이터 shape :  (50620, 8000)\n",
      "\n",
      "어떻게 생겼나? [-1.27418665e-04 -1.12644804e-04 -1.86756923e-04 ... -1.62762426e-05\n",
      " -4.93293861e-04 -3.55132594e-04]\n",
      "\n",
      "라벨 데이터 shape :  (50620, 1)\n",
      "\n",
      "어떻게 생겼나? ['down']\n"
     ]
    }
   ],
   "source": [
    "#wav_vals와 label_vals 인쇄\n",
    "print(\"음성 데이터 shape : \" ,speech_data[\"wav_vals\"].shape)\n",
    "print(\"\\n어떻게 생겼나?\" , speech_data[\"wav_vals\"][0])\n",
    "\n",
    "print(\"\\n라벨 데이터 shape : \" ,speech_data[\"label_vals\"].shape)\n",
    "print(\"\\n어떻게 생겼나?\" , speech_data[\"label_vals\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 인쇄해봤더니, 위와 같았다.     \n",
    "* 음성데이터는 (음성개수:50620개, 샘플링 레이트 8000)       \n",
    "* 라벨데이터는 (라벨개수:50620개, 라벨 값이 들어간 1개)   \n",
    "* 의 모양으로 생긴 것을 확인할 수 있다.       \n",
    "---\n",
    "__그럼 우리는 이제 spectogram 데이터가 어떤 모양인지 알아야 한다!__   \n",
    "\n",
    "![데이터 변환](./PostingPic/data.png)         \n",
    "\n",
    "* 사진을 보면, 노드에서 wav데이터를 spectogram으로 변환할 때     \n",
    "* Waveform shape(8000,) 스펙토그램(130,126)으로 바뀐 것을 알 수 있다.    \n",
    "* 그럼 일렬로 된 8000개의 샘플링 데이터를 -> 음성 1개당 (130,126)의 데이터로 변환시켜야 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.0723902e-03 5.2032182e-03 3.4693219e-03 ... 1.8922662e-02\n",
      "  3.3809434e-04 1.0142580e-02]\n",
      " [6.5486785e-03 3.2852096e-03 2.2495915e-03 ... 2.5527487e-02\n",
      "  1.6525777e-02 3.2326202e-03]\n",
      " [2.4226354e-03 3.5080472e-03 2.4726372e-03 ... 2.7952474e-02\n",
      "  2.6693283e-02 1.7628349e-02]\n",
      " ...\n",
      " [5.8292970e-04 2.9035914e-04 1.4131786e-05 ... 6.0245253e-05\n",
      "  3.1307511e-04 5.0933618e-04]\n",
      " [5.2434229e-04 2.5860392e-04 1.2995474e-05 ... 2.1275569e-05\n",
      "  2.2292971e-04 4.7651122e-04]\n",
      " [5.1448052e-04 2.5908535e-04 1.6500426e-06 ... 5.2643327e-06\n",
      "  2.3299157e-04 4.3895244e-04]]\n"
     ]
    }
   ],
   "source": [
    "#wav 데이터를 spectogram으로 변환한다.\n",
    "import librosa\n",
    "\n",
    "#wav 데이터를 spectogram 데이터로 바꾸는 매직\n",
    "#fft_size는 스펙토그램 사이즈를 맞추기 위해 258로 고정   \n",
    "def wav2spec(wav, fft_size=258):\n",
    "    D = np.abs(librosa.stft(wav, n_fft=fft_size))\n",
    "    return D\n",
    "\n",
    "#변환한 data를 담아줄 리스트\n",
    "specData =[]\n",
    "\n",
    "for wav_data in speech_data[\"wav_vals\"]:\n",
    "    specData.append(wav2spec(wav_data))\n",
    "    \n",
    "print(specData[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 리스트로 만들었으니, 이 리스트의 형태를 연산할 수 있게 np.array로 변환해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectrogram shape :  (50620, 130, 126)\n",
      "1개 데이터의 모양 :  (130, 126)\n"
     ]
    }
   ],
   "source": [
    "specData = np.array(specData)\n",
    "\n",
    "print(\"Spectrogram shape : \",specData.shape)\n",
    "print(\"1개 데이터의 모양 : \", specData[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 50620개의 데이터를 1데이터 당 (130,126) 사이즈로 변환했다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터 처리하기 - 1) 라벨 데이터 처리하기          \n",
    "\n",
    "* 그럼 이제 라벨 데이터도 같은 모양을 갖도록 처리해보자!     \n",
    "* 현재의 라벨 데이터 모양을 출력해본다.       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50620, 1)\n"
     ]
    }
   ],
   "source": [
    "print(speech_data[\"label_vals\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 라벨 데이터의 종류들을 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['down' 'go' 'left' 'no' 'off' 'on' 'right' 'silence' 'stop' 'unknown'\n",
      " 'up' 'yes']\n"
     ]
    }
   ],
   "source": [
    "label_list = np.unique(speech_data[\"label_vals\"])\n",
    "print(label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 이 12개의 데이터들을, 학습에 사용하기 위해 딕셔너리 형태로 바꿔준다.    \n",
    "* 단, 현재 0:down, 1:go.... 로 되어있는 리스트를 거꾸로 down:0 이 되도록 바꿔주어야 컴퓨터가 처리 가능하다.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indexed labels :  {'down': 0, 'go': 1, 'left': 2, 'no': 3, 'off': 4, 'on': 5, 'right': 6, 'silence': 7, 'stop': 8, 'unknown': 9, 'up': 10, 'yes': 11}\n"
     ]
    }
   ],
   "source": [
    "label_data_dict = dict() \n",
    "\n",
    "for i, l in enumerate(label_list):\n",
    "    label_data_dict[l] = i\n",
    "    \n",
    "label_list = label_data_dict\n",
    "\n",
    "print(\"indexed labels : \" , label_data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 12개의 라벨이 모두 __라벨(str값):인덱스  의 형태로 변환__ 된 것을 확인할 수 있다.     \n",
    "* 여기서 다시 라벨을 연산이 가능한 np.array 형태로 바꿔준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전부 다 변환됐는가? :  50620\n",
      "(50620,)\n",
      "몇 개만 출력해보자  0 1\n"
     ]
    }
   ],
   "source": [
    "temp = []\n",
    "\n",
    "for value in speech_data[\"label_vals\"]:\n",
    "    temp.append(label_list[value[0]])\n",
    "\n",
    "print(\"전부 다 변환됐는가? : \" , len(temp))\n",
    "label_data = np.array(temp)\n",
    "\n",
    "print(label_data.shape)\n",
    "print(\"몇 개만 출력해보자 \" ,  label_data[9] , label_data[2850])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 확인해보니, 50620개의 데이터가 모두 label_data 형태로 변환되었음을 알 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.데이터 처리하기 - 2. 학습 데이터, 테스트 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터 수 45558\n",
      "train_spec :  (45558, 130, 126, 1)\n",
      "train_label : (45558,)\n",
      "test_spec :  (5062, 130, 126, 1)\n",
      "test_label : (5062,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#차원 알려주기\n",
    "sp_s=130\n",
    "sp_p=126\n",
    "\n",
    "# 학습데이터:테스트데이터 = 9:1 로 해 보았다 ㅎㅎ\n",
    "train_spec, test_spec, train_label, test_label = train_test_split(specData, label_data, test_size=0.1, shuffle=True)\n",
    "print(\"학습 데이터 수\", len(train_spec))\n",
    "\n",
    "train_spec = train_spec.reshape([-1, sp_s, sp_p,1])\n",
    "test_spec = test_spec.reshape([-1, sp_s, sp_p,1])\n",
    "\n",
    "#나눠진 데이터 모습을 확인해보자.\n",
    "print(\"train_spec : \", train_spec.shape)\n",
    "print(\"train_label :\" , train_label.shape)\n",
    "print(\"test_spec : \", test_spec.shape)\n",
    "print(\"test_label :\", test_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 학습을 위한 하이퍼파라미터 설정          \n",
    "\n",
    "* 혹시 모르는 마음에, 기본적인 설정은 노드와 동일하게 진행해주었다.      \n",
    "* 추후 성능에 따라 하이퍼파라미터를 조정해주도록 한다.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ssac23/SUBMIT_MISSION_GIT/ex5_STT/model/wav'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "max_epoch = 10\n",
    "\n",
    "#중간중간 저장해줄 체크포인트 생성\n",
    "check_path = os.getenv('HOME')+'/SUBMIT_MISSION_GIT/ex5_STT/model/wav'\n",
    "\n",
    "check_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 데이터셋 구성 - 1) 데이터셋 구성     \n",
    "\n",
    "---\n",
    "__요건__       \n",
    "* tf.data.Dataset을 이용        \n",
    "* from_tensor_slices에 return 받길 원하는 데이터를 튜플 형태로 받음     \n",
    "* map과 batch를 사용한 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot_label\n"
     ]
    }
   ],
   "source": [
    "#정답 라벨 말고는 다 죽이는 one_hot_label\n",
    "def one_hot_label(spec,label):\n",
    "    \n",
    "    #depth=12는 최종 결과값이 12개 나온다는 의미(물론 뒤에 1차원이 더 붙는다.)\n",
    "    #우리 라벨 데이터는 12개이므로 depth=12임!\n",
    "    label = tf.one_hot(label, depth=12)\n",
    "    return spec, label\n",
    "\n",
    "print(\"one_hot_label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((None, 130, 126, 1), (None, 12)), types: (tf.float32, tf.float32)>\n",
      "<BatchDataset shapes: ((None, 130, 126, 1), (None, 12)), types: (tf.float32, tf.float32)>\n",
      "데이터 처리 완료\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_spec, train_label))\n",
    "train_dataset = train_dataset.map(one_hot_label)\n",
    "train_dataset = train_dataset.repeat().batch(batch_size=batch_size)\n",
    "print(train_dataset)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_spec, test_label))\n",
    "test_dataset = test_dataset.map(one_hot_label)\n",
    "test_dataset = test_dataset.batch(batch_size=batch_size)\n",
    "print(test_dataset)\n",
    "\n",
    "print(\"데이터 처리 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__메모리 비우기 수행하기__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "비우기 완료!\n"
     ]
    }
   ],
   "source": [
    "del speech_data\n",
    "del specData\n",
    "print(\"비우기 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 2차원 Spectogram 데이터를 처리하는 모델 구성      \n",
    "---   \n",
    "__요건__     \n",
    "* 2차원 spectogram 데이터의 시간축 방향으로 Conv1D 혹은 Conv2D 레이어를 적용 가능   \n",
    "* batchnorm, dropout, dense layer를 이용    \n",
    "* 12개의 단어 class를 구분하는 loss를 사용하고, Adam optimizer 사용     \n",
    "* 모델 가중치를 저장하는 checkpoint callback 함수 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Conv2D 레이어__ 를 적용해보기로 했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 130, 126, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 130, 126, 32)      320       \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 130, 126, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 65, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 65, 63, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 65, 63, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 32, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 32, 31, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 32, 31, 128)       147584    \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 32, 31, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 16, 15, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 16, 15, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 16, 15, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 16, 15, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 8, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 14336)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               3670272   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 12)                3084      \n",
      "=================================================================\n",
      "Total params: 5,583,724\n",
      "Trainable params: 5,583,212\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "#spec_data의 형태를 알려준다.\n",
    "input_tensor = layers.Input(shape=(sp_s, sp_p, 1))\n",
    "\n",
    "x = layers.Conv2D(32, 3, padding='same', activation='relu')(input_tensor)\n",
    "x = layers.Conv2D(32, 3, padding='same', activation='relu')(x)\n",
    "x = layers.MaxPool2D()(x)\n",
    "\n",
    "x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "x = layers.MaxPool2D()(x)\n",
    "\n",
    "x = layers.Conv2D(128, 3, padding='same', activation='relu')(x)\n",
    "x = layers.Conv2D(128, 3, padding='same', activation='relu')(x)\n",
    "x = layers.Conv2D(128, 3, padding='same', activation='relu')(x)\n",
    "x = layers.MaxPool2D()(x)\n",
    "\n",
    "x = layers.Conv2D(256, 3, padding='same', activation='relu')(x)\n",
    "x = layers.Conv2D(256, 3, padding='same', activation='relu')(x)\n",
    "x = layers.Conv2D(256, 3, padding='same', activation='relu')(x)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(256)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "\n",
    "output_tensor = layers.Dense(12)(x)\n",
    "\n",
    "model_spec = tf.keras.Model(input_tensor, output_tensor)\n",
    "\n",
    "model_spec.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 진행하면서 conv1D -> conv2D로 바꿀 때 뭐가 필요할까? 라고 찾아보던 와중에     \n",
    "* 커널 사이즈가 궁금해서 검색했더니 이런 답이 있었다.     \n",
    "\n",
    "[커널 사이즈란 이런 것이다](https://stats.stackexchange.com/questions/296679/what-does-kernel-size-mean)     \n",
    "\n",
    "* 인상적이어서 적어둠... 그리고 원래 소스코드에서는 커널이 9였는데,   \n",
    "* 위의 글에서는 1, 2, or 3같은 넘버로 해라.. 적혀있어서 일단 3으로 바꿔보았다.(개중에 제일 큰것같아서..)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 모델 구성 - 2) 손실함수 구성       \n",
    "---\n",
    "__요건__    \n",
    "* 12개의 단어 클래스를 구분하는 loss를 사용하고, Adam optimizer 사용  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "손실함수 구성 완료\n"
     ]
    }
   ],
   "source": [
    "optimizer=tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "#multi-class classification에 사용된다는 CategorialCrossentropy\n",
    "#여담이지만 docs에 Categorical_Crossentropy도 있었다.\n",
    "#CategoricalCrossentropy -> computes the crossentropy loss between the labels and predictions\n",
    "model_spec.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "             optimizer=optimizer,\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "print(\"손실함수 구성 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 모델 구성 - 3) 모델 가중치를 저장하기 위한 콜백함수 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가중치 저장을 위한 콜백함수 설정 완료\n"
     ]
    }
   ],
   "source": [
    "spec_callback = tf.keras.callbacks.ModelCheckpoint(check_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 monitor='val_loss',\n",
    "                                                 mode='auto',\n",
    "                                                 save_best_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "print(\"가중치 저장을 위한 콜백함수 설정 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 이제 드디어, 모델 학습...! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch=32, epoch=10\n",
    "history_spec = model_spec.fit(train_dataset, epochs=max_epochs,\n",
    "                    steps_per_epoch=len(train_wav) // batch_size,\n",
    "                    validation_data=test_dataset,\n",
    "                    validation_steps=len(test_wav) // batch_size,\n",
    "                    callbacks=[spec_callback]\n",
    "                    )\n",
    "\n",
    "print(\"모델 학습\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
