{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration 05_ STT        \n",
    "---\n",
    "## 이 노드의 루브릭      \n",
    "1. 음성데이터를 2차원 Spectogram으로 변환하여 데이터셋을 구성하였다.      \n",
    "    -> \"스펙토그램 시각화 및 train/test 데이터셋 구성이 정상 진행되었다.\"    \n",
    "    \n",
    "    \n",
    "2. 1, 2차원 데이터를 처리하는 음성인식 모델이 정상 작동한다.          \n",
    "    -> \"스펙토그램을 입력받은 모델이 학습 과정에서 안정적으로 수렴하며, evaluation/test 단계를 무리없이 진행 가능하다.      \n",
    "    \n",
    "    \n",
    "    \n",
    "3. 테스트셋 수행 결과 음성인식 모델의 Accuracy가 일정 수준에 도달하였다.     \n",
    "    -> \"평가 결과 75% 이상의 정확도를 달성하는 모델이 하나 이상 존재한다.\"    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 목차       \n",
    "\n",
    "1. 데이터 처리와 분류    \n",
    "  - 라벨 데이터 처리하기\n",
    "  - sklearn의 train_test_split 함수를 이용하여 train, test 분리   \n",
    "2. 학습을 위한 하이퍼파라미터 설정     \n",
    "3. 데이터셋 구성        \n",
    "  - tf.data.Dataset을 이용       \n",
    "  - from_tensor_slices에 return 받길 원하는 데이터를 튜플 형태로 받음   \n",
    "  - map과 batch를 사용한 데이터 전처리.\n",
    "  - 메모리 비우기 수행하기    \n",
    "  \n",
    "  > del speech_data\n",
    "  > del spec_data\n",
    "  \n",
    "4. 2차원 Spectogram 데이터를 처리하는 모델 구성     \n",
    "  - 2차원 Spectogram 데이터의 시간축 방향으로 Conv1D/Conv2D 레이어를 적용가능    \n",
    "  - batchnorm, dropout, dense layer 를 이용    \n",
    "  - 12개의 단어 class를 구분하는 loss를 사용하고, Adam optimizer 사용   \n",
    "  - 모델 가중치를 저장하는 checkpoint callback 함수 추가     \n",
    "  \n",
    "5. 학습 내용 그래프 출력\n",
    "  - loss, accuracy를 그래프로 표현     \n",
    "  \n",
    "6. Test dataset을 이용한 모델의 성능 평가   \n",
    "  - 저장한 weight 불러오기    \n",
    "  - 모델의 예측값과 정답값이 얼마나 맞는지 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터 처리와 분류      \n",
    "##### 데이터 가져오기       \n",
    "* 기존에는 Waveform 데이터로 입력받아, Text라벨을 출력하는 모델을 만들었다.    \n",
    "* 이제 이 데이터를 Spectogram으로 입력받아, 동일 역할을 수행하는 모델을 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터를 가져왔다!\n",
      "wav 상태 그대로의 데이터 셰이프 : (50620, 8000)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "data_path = os.getenv(\"HOME\")+'/SUBMIT_MISSION_GIT/ex5_STT/data/speech_wav_8000.npz'\n",
    "speech_data = np.load(data_path)\n",
    "\n",
    "print(\"데이터를 가져왔다!\")\n",
    "print(\"wav 상태 그대로의 데이터 셰이프 :\", speech_data[\"wav_vals\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 내겐 너무 어려웠던 데이터 형변환         \n",
    "* 사실, speech_data -> spectogram data로 형변환하는 과정이 너무 어려웠다.   \n",
    "* 하나하나씩 차근히 분해해보기로 했다.         \n",
    "---\n",
    "1. 일단, speech_data를 이루고 있는 저 npz 확장자는 대체 무엇인지     \n",
    "* npz 파일 포맷은 여러 개의 리스트를 한번에 저장하기 위한 포맷이다.     \n",
    "* 그렇군.      \n",
    "---\n",
    "* 그럼, 얘 안에 들어있는 데이터들은 뭘까?      \n",
    "* 위에서 speech_data를 살펴보았을 때, 데이터는     \n",
    "* speech_data[\"wav_vals\"]와 speech_data[\"label_vals\"]가 있었다.    \n",
    "* wav_vals는 음성 데이터, label_vals는 음성의 뜻을 의미하는 라벨 데이터이다.  \n",
    "* 프린트해서 다시 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "음성 데이터 shape :  (50620, 8000)\n",
      "\n",
      "어떻게 생겼나? [-1.27418665e-04 -1.12644804e-04 -1.86756923e-04 ... -1.62762426e-05\n",
      " -4.93293861e-04 -3.55132594e-04]\n",
      "\n",
      "라벨 데이터 shape :  (50620, 1)\n",
      "\n",
      "어떻게 생겼나? ['down']\n"
     ]
    }
   ],
   "source": [
    "#wav_vals와 label_vals 인쇄\n",
    "print(\"음성 데이터 shape : \" ,speech_data[\"wav_vals\"].shape)\n",
    "print(\"\\n어떻게 생겼나?\" , speech_data[\"wav_vals\"][0])\n",
    "\n",
    "print(\"\\n라벨 데이터 shape : \" ,speech_data[\"label_vals\"].shape)\n",
    "print(\"\\n어떻게 생겼나?\" , speech_data[\"label_vals\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 인쇄해봤더니, 위와 같았다.     \n",
    "* 음성데이터는 (음성개수:50620개, 샘플링 레이트 8000)       \n",
    "* 라벨데이터는 (라벨개수:50620개, 라벨 값이 들어간 1개)   \n",
    "* 의 모양으로 생긴 것을 확인할 수 있다.       \n",
    "---\n",
    "__그럼 우리는 이제 spectogram 데이터가 어떤 모양인지 알아야 한다!__   \n",
    "\n",
    "![데이터 변환](./PostingPic/data.png)         \n",
    "\n",
    "* 사진을 보면, 노드에서 wav데이터를 spectogram으로 변환할 때     \n",
    "* Waveform shape(8000,) 스펙토그램(130,126)으로 바뀐 것을 알 수 있다.    \n",
    "* 그럼 일렬로 된 8000개의 샘플링 데이터를 -> 음성 1개당 (130,126)의 데이터로 변환시켜야 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.0723902e-03 5.2032182e-03 3.4693219e-03 ... 1.8922662e-02\n",
      "  3.3809434e-04 1.0142580e-02]\n",
      " [6.5486785e-03 3.2852096e-03 2.2495915e-03 ... 2.5527487e-02\n",
      "  1.6525777e-02 3.2326202e-03]\n",
      " [2.4226354e-03 3.5080472e-03 2.4726372e-03 ... 2.7952474e-02\n",
      "  2.6693283e-02 1.7628349e-02]\n",
      " ...\n",
      " [5.8292970e-04 2.9035914e-04 1.4131786e-05 ... 6.0245253e-05\n",
      "  3.1307511e-04 5.0933618e-04]\n",
      " [5.2434229e-04 2.5860392e-04 1.2995474e-05 ... 2.1275569e-05\n",
      "  2.2292971e-04 4.7651122e-04]\n",
      " [5.1448052e-04 2.5908535e-04 1.6500426e-06 ... 5.2643327e-06\n",
      "  2.3299157e-04 4.3895244e-04]]\n"
     ]
    }
   ],
   "source": [
    "#wav 데이터를 spectogram으로 변환한다.\n",
    "import librosa\n",
    "\n",
    "#wav 데이터를 spectogram 데이터로 바꾸는 매직\n",
    "#fft_size는 스펙토그램 사이즈를 맞추기 위해 258로 고정   \n",
    "def wav2spec(wav, fft_size=258):\n",
    "    D = np.abs(librosa.stft(wav, n_fft=fft_size))\n",
    "    return D\n",
    "\n",
    "#변환한 data를 담아줄 리스트\n",
    "specData =[]\n",
    "\n",
    "for wav_data in speech_data[\"wav_vals\"]:\n",
    "    specData.append(wav2spec(wav_data))\n",
    "    \n",
    "print(specData[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 리스트로 만들었으니, 이 리스트의 형태를 연산할 수 있게 np.array로 변환해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectrogram shape :  (50620, 130, 126)\n",
      "1개 데이터의 모양 :  (130, 126)\n"
     ]
    }
   ],
   "source": [
    "specData = np.array(specData)\n",
    "\n",
    "print(\"Spectrogram shape : \",specData.shape)\n",
    "print(\"1개 데이터의 모양 : \", specData[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 50620개의 데이터를 1데이터 당 (130,126) 사이즈로 변환했다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터 처리하기 - 1) 라벨 데이터 처리하기          \n",
    "\n",
    "* 그럼 이제 라벨 데이터도 같은 모양을 갖도록 처리해보자!     \n",
    "* 현재의 라벨 데이터 모양을 출력해본다.       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50620, 1)\n"
     ]
    }
   ],
   "source": [
    "print(speech_data[\"label_vals\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 라벨 데이터의 종류들을 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['down' 'go' 'left' 'no' 'off' 'on' 'right' 'silence' 'stop' 'unknown'\n",
      " 'up' 'yes']\n"
     ]
    }
   ],
   "source": [
    "label_list = np.unique(speech_data[\"label_vals\"])\n",
    "print(label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 이 12개의 데이터들을, 학습에 사용하기 위해 딕셔너리 형태로 바꿔준다.    \n",
    "* 단, 현재 0:down, 1:go.... 로 되어있는 리스트를 거꾸로 down:0 이 되도록 바꿔주어야 컴퓨터가 처리 가능하다.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indexed labels :  {'down': 0, 'go': 1, 'left': 2, 'no': 3, 'off': 4, 'on': 5, 'right': 6, 'silence': 7, 'stop': 8, 'unknown': 9, 'up': 10, 'yes': 11}\n"
     ]
    }
   ],
   "source": [
    "label_data_dict = dict() \n",
    "\n",
    "for i, l in enumerate(label_list):\n",
    "    label_data_dict[l] = i\n",
    "    \n",
    "label_list = label_data_dict\n",
    "\n",
    "print(\"indexed labels : \" , label_data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 12개의 라벨이 모두 __라벨(str값):인덱스  의 형태로 변환__ 된 것을 확인할 수 있다.     \n",
    "* 여기서 다시 라벨을 연산이 가능한 np.array 형태로 바꿔준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전부 다 변환됐는가? :  50620\n",
      "(50620,)\n",
      "몇 개만 출력해보자  0 1\n"
     ]
    }
   ],
   "source": [
    "temp = []\n",
    "\n",
    "for value in speech_data[\"label_vals\"]:\n",
    "    temp.append(label_list[value[0]])\n",
    "\n",
    "print(\"전부 다 변환됐는가? : \" , len(temp))\n",
    "label_data = np.array(temp)\n",
    "\n",
    "print(label_data.shape)\n",
    "print(\"몇 개만 출력해보자 \" ,  label_data[9] , label_data[2850])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 확인해보니, 50620개의 데이터가 모두 label_data 형태로 변환되었음을 알 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.데이터 처리하기 - 2. 학습 데이터, 테스트 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터 수 45558\n",
      "train_spec :  (45558, 130, 126, 1)\n",
      "train_label : (45558,)\n",
      "test_spec :  (5062, 130, 126, 1)\n",
      "test_label : (5062,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#차원 알려주기\n",
    "sp_s=130\n",
    "sp_p=126\n",
    "\n",
    "# 학습데이터:테스트데이터 = 9:1 로 해 보았다 ㅎㅎ\n",
    "train_spec, test_spec, train_label, test_label = train_test_split(specData, label_data, test_size=0.1, shuffle=True)\n",
    "print(\"학습 데이터 수\", len(train_spec))\n",
    "\n",
    "train_spec = train_spec.reshape([-1, sp_s, sp_p,1])\n",
    "test_spec = test_spec.reshape([-1, sp_s, sp_p,1])\n",
    "\n",
    "#나눠진 데이터 모습을 확인해보자.\n",
    "print(\"train_spec : \", train_spec.shape)\n",
    "print(\"train_label :\" , train_label.shape)\n",
    "print(\"test_spec : \", test_spec.shape)\n",
    "print(\"test_label :\", test_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 학습을 위한 하이퍼파라미터 설정          \n",
    "\n",
    "* 혹시 모르는 마음에, 기본적인 설정은 노드와 동일하게 진행해주었다.      \n",
    "* 추후 성능에 따라 하이퍼파라미터를 조정해주도록 한다.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ssac23/SUBMIT_MISSION_GIT/ex5_STT/model/wav'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "max_epoch = 10\n",
    "\n",
    "#중간중간 저장해줄 체크포인트 생성\n",
    "check_path = os.getenv('HOME')+'/SUBMIT_MISSION_GIT/ex5_STT/model/wav'\n",
    "\n",
    "check_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 데이터셋 구성 - 1) 데이터셋 구성     \n",
    "\n",
    "---\n",
    "__요건__       \n",
    "* tf.data.Dataset을 이용        \n",
    "* from_tensor_slices에 return 받길 원하는 데이터를 튜플 형태로 받음     \n",
    "* map과 batch를 사용한 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot_label\n"
     ]
    }
   ],
   "source": [
    "#정답 라벨 말고는 다 죽이는 one_hot_label\n",
    "def one_hot_label(spec,label):\n",
    "    \n",
    "    #depth=12는 최종 결과값이 12개 나온다는 의미(물론 뒤에 1차원이 더 붙는다.)\n",
    "    #우리 라벨 데이터는 12개이므로 depth=12임!\n",
    "    label = tf.one_hot(label, depth=12)\n",
    "    return spec, label\n",
    "\n",
    "print(\"one_hot_label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((None, 130, 126, 1), (None, 12)), types: (tf.float32, tf.float32)>\n",
      "<BatchDataset shapes: ((None, 130, 126, 1), (None, 12)), types: (tf.float32, tf.float32)>\n",
      "데이터 처리 완료\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_spec, train_label))\n",
    "train_dataset = train_dataset.map(one_hot_label)\n",
    "train_dataset = train_dataset.repeat().batch(batch_size=batch_size)\n",
    "print(train_dataset)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_spec, test_label))\n",
    "test_dataset = test_dataset.map(one_hot_label)\n",
    "test_dataset = test_dataset.batch(batch_size=batch_size)\n",
    "print(test_dataset)\n",
    "\n",
    "print(\"데이터 처리 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__메모리 비우기 수행하기__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "비우기 완료!\n"
     ]
    }
   ],
   "source": [
    "del speech_data\n",
    "del specData\n",
    "print(\"비우기 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 2차원 Spectogram 데이터를 처리하는 모델 구성      \n",
    "---   \n",
    "__요건__     \n",
    "* 2차원 spectogram 데이터의 시간축 방향으로 Conv1D 혹은 Conv2D 레이어를 적용 가능   \n",
    "* batchnorm, dropout, dense layer를 이용    \n",
    "* 12개의 단어 class를 구분하는 loss를 사용하고, Adam optimizer 사용     \n",
    "* 모델 가중치를 저장하는 checkpoint callback 함수 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Conv2D 레이어__ 를 적용해보기로 했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 130, 126, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 130, 126, 32)      320       \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 130, 126, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 65, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 65, 63, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 65, 63, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 32, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 32, 31, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 32, 31, 128)       147584    \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 32, 31, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 16, 15, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 16, 15, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 16, 15, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 16, 15, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 8, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 14336)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               3670272   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 12)                3084      \n",
      "=================================================================\n",
      "Total params: 5,583,724\n",
      "Trainable params: 5,583,212\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "#spec_data의 형태를 알려준다.\n",
    "input_tensor = layers.Input(shape=(sp_s, sp_p, 1))\n",
    "\n",
    "x = layers.Conv2D(32, 3, padding='same', activation='relu')(input_tensor)\n",
    "x = layers.Conv2D(32, 3, padding='same', activation='relu')(x)\n",
    "x = layers.MaxPool2D()(x)\n",
    "\n",
    "x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "x = layers.MaxPool2D()(x)\n",
    "\n",
    "x = layers.Conv2D(128, 3, padding='same', activation='relu')(x)\n",
    "x = layers.Conv2D(128, 3, padding='same', activation='relu')(x)\n",
    "x = layers.Conv2D(128, 3, padding='same', activation='relu')(x)\n",
    "x = layers.MaxPool2D()(x)\n",
    "\n",
    "x = layers.Conv2D(256, 3, padding='same', activation='relu')(x)\n",
    "x = layers.Conv2D(256, 3, padding='same', activation='relu')(x)\n",
    "x = layers.Conv2D(256, 3, padding='same', activation='relu')(x)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(256)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "\n",
    "output_tensor = layers.Dense(12)(x)\n",
    "\n",
    "model_spec = tf.keras.Model(input_tensor, output_tensor)\n",
    "\n",
    "model_spec.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 진행하면서 conv1D -> conv2D로 바꿀 때 뭐가 필요할까? 라고 찾아보던 와중에     \n",
    "* 커널 사이즈가 궁금해서 검색했더니 이런 답이 있었다.     \n",
    "\n",
    "[커널 사이즈란 이런 것이다](https://stats.stackexchange.com/questions/296679/what-does-kernel-size-mean)     \n",
    "\n",
    "* 인상적이어서 적어둠... 그리고 원래 소스코드에서는 커널이 9였는데,   \n",
    "* 위의 글에서는 1, 2, or 3같은 넘버로 해라.. 적혀있어서 일단 3으로 바꿔보았다.(개중에 제일 큰것같아서..)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 모델 구성 - 2) 손실함수 구성       \n",
    "---\n",
    "__요건__    \n",
    "* 12개의 단어 클래스를 구분하는 loss를 사용하고, Adam optimizer 사용  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "손실함수 구성 완료\n"
     ]
    }
   ],
   "source": [
    "optimizer=tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "#multi-class classification에 사용된다는 CategorialCrossentropy\n",
    "#여담이지만 docs에 Categorical_Crossentropy도 있었다.\n",
    "#CategoricalCrossentropy -> computes the crossentropy loss between the labels and predictions\n",
    "model_spec.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "             optimizer=optimizer,\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "print(\"손실함수 구성 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 모델 구성 - 3) 모델 가중치를 저장하기 위한 콜백함수 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가중치 저장을 위한 콜백함수 설정 완료\n"
     ]
    }
   ],
   "source": [
    "spec_callback = tf.keras.callbacks.ModelCheckpoint(check_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 monitor='val_loss',\n",
    "                                                 mode='auto',\n",
    "                                                 save_best_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "print(\"가중치 저장을 위한 콜백함수 설정 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 이제 드디어, 모델 학습...! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1423/1423 [==============================] - ETA: 0s - loss: 0.7550 - accuracy: 0.7571\n",
      "Epoch 00001: val_loss improved from inf to 0.43234, saving model to /home/ssac23/SUBMIT_MISSION_GIT/ex5_STT/model/wav\n",
      "1423/1423 [==============================] - 61s 43ms/step - loss: 0.7550 - accuracy: 0.7571 - val_loss: 0.4323 - val_accuracy: 0.8663\n",
      "Epoch 2/10\n",
      "1423/1423 [==============================] - ETA: 0s - loss: 0.2612 - accuracy: 0.9210\n",
      "Epoch 00002: val_loss improved from 0.43234 to 0.24977, saving model to /home/ssac23/SUBMIT_MISSION_GIT/ex5_STT/model/wav\n",
      "1423/1423 [==============================] - 61s 43ms/step - loss: 0.2612 - accuracy: 0.9210 - val_loss: 0.2498 - val_accuracy: 0.9233\n",
      "Epoch 3/10\n",
      "1423/1423 [==============================] - ETA: 0s - loss: 0.1643 - accuracy: 0.9513\n",
      "Epoch 00003: val_loss improved from 0.24977 to 0.18675, saving model to /home/ssac23/SUBMIT_MISSION_GIT/ex5_STT/model/wav\n",
      "1423/1423 [==============================] - 61s 43ms/step - loss: 0.1643 - accuracy: 0.9513 - val_loss: 0.1867 - val_accuracy: 0.9357\n",
      "Epoch 4/10\n",
      "1423/1423 [==============================] - ETA: 0s - loss: 0.1200 - accuracy: 0.9645\n",
      "Epoch 00004: val_loss improved from 0.18675 to 0.14514, saving model to /home/ssac23/SUBMIT_MISSION_GIT/ex5_STT/model/wav\n",
      "1423/1423 [==============================] - 61s 43ms/step - loss: 0.1200 - accuracy: 0.9645 - val_loss: 0.1451 - val_accuracy: 0.9490\n",
      "Epoch 5/10\n",
      "1423/1423 [==============================] - ETA: 0s - loss: 0.0920 - accuracy: 0.9724\n",
      "Epoch 00005: val_loss improved from 0.14514 to 0.12152, saving model to /home/ssac23/SUBMIT_MISSION_GIT/ex5_STT/model/wav\n",
      "1423/1423 [==============================] - 62s 43ms/step - loss: 0.0920 - accuracy: 0.9724 - val_loss: 0.1215 - val_accuracy: 0.9591\n",
      "Epoch 6/10\n",
      "1423/1423 [==============================] - ETA: 0s - loss: 0.0775 - accuracy: 0.9761\n",
      "Epoch 00006: val_loss did not improve from 0.12152\n",
      "1423/1423 [==============================] - 61s 43ms/step - loss: 0.0775 - accuracy: 0.9761 - val_loss: 0.1521 - val_accuracy: 0.9535\n",
      "Epoch 7/10\n",
      "1423/1423 [==============================] - ETA: 0s - loss: 0.0633 - accuracy: 0.9812\n",
      "Epoch 00007: val_loss improved from 0.12152 to 0.11315, saving model to /home/ssac23/SUBMIT_MISSION_GIT/ex5_STT/model/wav\n",
      "1423/1423 [==============================] - 61s 43ms/step - loss: 0.0633 - accuracy: 0.9812 - val_loss: 0.1132 - val_accuracy: 0.9628\n",
      "Epoch 8/10\n",
      "1423/1423 [==============================] - ETA: 0s - loss: 0.0544 - accuracy: 0.9837\n",
      "Epoch 00008: val_loss did not improve from 0.11315\n",
      "1423/1423 [==============================] - 61s 43ms/step - loss: 0.0544 - accuracy: 0.9837 - val_loss: 0.1228 - val_accuracy: 0.9593\n",
      "Epoch 9/10\n",
      "1423/1423 [==============================] - ETA: 0s - loss: 0.0480 - accuracy: 0.9853\n",
      "Epoch 00009: val_loss improved from 0.11315 to 0.10859, saving model to /home/ssac23/SUBMIT_MISSION_GIT/ex5_STT/model/wav\n",
      "1423/1423 [==============================] - 61s 43ms/step - loss: 0.0480 - accuracy: 0.9853 - val_loss: 0.1086 - val_accuracy: 0.9652\n",
      "Epoch 10/10\n",
      "1423/1423 [==============================] - ETA: 0s - loss: 0.0399 - accuracy: 0.9882\n",
      "Epoch 00010: val_loss did not improve from 0.10859\n",
      "1423/1423 [==============================] - 61s 43ms/step - loss: 0.0399 - accuracy: 0.9882 - val_loss: 0.1290 - val_accuracy: 0.9597\n",
      "모델 학습\n"
     ]
    }
   ],
   "source": [
    "#batch=32, epoch=10\n",
    "history_spec = model_spec.fit(train_dataset, epochs=10,\n",
    "                    steps_per_epoch=len(train_spec) // batch_size,\n",
    "                    validation_data=test_dataset,\n",
    "                    validation_steps=len(test_spec) // batch_size,\n",
    "                    callbacks=[spec_callback]\n",
    "                    )\n",
    "\n",
    "print(\"모델 학습\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 학습이 무사히 끝났고, 학습 결과를 시각화 해 보도록 하겠다.     \n",
    "\n",
    "### 5. 학습 내용 그래프로 출력      \n",
    "\n",
    "* loss, accuracy를 그래프로 표현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#정확도와 손실율을 각 변수에 배정\n",
    "acc = history_spec.history['accuracy']\n",
    "val_acc = history_spec.history['val_accuracy']\n",
    "\n",
    "loss=history_spec.history['loss']\n",
    "val_loss=history_spec.history['val_loss']\n",
    "\n",
    "epochs_range = range(len(acc))\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* train loss와 validation loss가 크게 벌어지면 오버피팅 가능성이 있다.      \n",
    "* epoch=4 이후로 격차가 크게 벌어졌다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Test Dataset을 이용한 모델의 성능 평가 - 1) 저장한 weight 불러오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이전 기록을 가져왔다.\n"
     ]
    }
   ],
   "source": [
    "#우리가 콜백 함수를 통해 저장한 weight를 가져와보도록 하자.\n",
    "\n",
    "model_spec.load_weights(check_path)\n",
    "\n",
    "print(\"이전 기록을 가져왔다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Test Dataset을 이용한 모델의 성능 평가 2) 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 33s 205ms/step - loss: 0.1085 - accuracy: 0.9652\n",
      "테스트 데이터셋으로 평가해보자.\n",
      "\n",
      "loss value : 0.108\n",
      "\n",
      "acuuracy value : 96.5231\n"
     ]
    }
   ],
   "source": [
    "results = model_spec.evaluate(test_dataset)\n",
    "print(\"테스트 데이터셋으로 평가해보자.\")\n",
    "\n",
    "#로스\n",
    "print(\"\\nloss value : {:.3f}\".format(results[0]))\n",
    "\n",
    "#정확도\n",
    "print(\"\\nacuuracy value : {:.4f}\".format(results[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 정확도가 96.5로 나왔다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 번외. Skip-connection 모델을 적용하여 정확도를 개선해보자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 130, 126, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 130, 126, 32) 320         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 130, 126, 32) 9248        conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling2D) (None, 65, 63, 32)   0           conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 65, 63, 64)   18496       max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 65, 63, 64)   36928       conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_3 (TensorFlo [(None, 65, 63, 96)] 0           conv2d_50[0][0]                  \n",
      "                                                                 max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling2D) (None, 32, 31, 96)   0           tf_op_layer_concat_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 32, 31, 128)  110720      max_pooling2d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 32, 31, 128)  147584      conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 32, 31, 128)  147584      conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_4 (TensorFlo [(None, 32, 31, 224) 0           conv2d_53[0][0]                  \n",
      "                                                                 max_pooling2d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling2D) (None, 16, 15, 224)  0           tf_op_layer_concat_4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 16, 15, 256)  516352      max_pooling2d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 16, 15, 256)  590080      conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 16, 15, 256)  590080      conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_5 (TensorFlo [(None, 16, 15, 480) 0           conv2d_56[0][0]                  \n",
      "                                                                 max_pooling2d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling2D) (None, 8, 7, 480)    0           tf_op_layer_concat_5[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 8, 7, 480)    0           max_pooling2d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 26880)        0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 256)          6881536     flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 256)          1024        dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 256)          0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 12)           3084        activation_4[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 9,053,036\n",
      "Trainable params: 9,052,524\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#skip-connection은  기존의 인풋값을 기억하여 변동된 값만을 추가학습하도록 하는 방법 \n",
    "#y=f(x)+x\n",
    "input_tensor = layers.Input(shape=(sp_s, sp_p, 1))\n",
    "\n",
    "x = layers.Conv2D(32, 3, padding='same', activation='relu')(input_tensor)\n",
    "x = layers.Conv2D(32, 3, padding='same', activation='relu')(x)\n",
    "skip_1 = layers.MaxPool2D()(x)\n",
    "\n",
    "x = layers.Conv2D(64, 3, padding='same', activation='relu')(skip_1)\n",
    "x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "x = tf.concat([x, skip_1], -1)\n",
    "skip_2 = layers.MaxPool2D()(x)\n",
    "\n",
    "x = layers.Conv2D(128, 3, padding='same', activation='relu')(skip_2)\n",
    "x = layers.Conv2D(128, 3, padding='same', activation='relu')(x)\n",
    "x = layers.Conv2D(128, 3, padding='same', activation='relu')(x)\n",
    "x = tf.concat([x, skip_2], -1)\n",
    "skip_3 = layers.MaxPool2D()(x)\n",
    "\n",
    "x = layers.Conv2D(256, 3, padding='same', activation='relu')(skip_3)\n",
    "x = layers.Conv2D(256, 3, padding='same', activation='relu')(x)\n",
    "x = layers.Conv2D(256, 3, padding='same', activation='relu')(x)\n",
    "x = tf.concat([x, skip_3], -1)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(256)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "\n",
    "output_tensor = layers.Dense(12)(x)\n",
    "\n",
    "model_spec_skip2 = tf.keras.Model(input_tensor, output_tensor)\n",
    "\n",
    "model_spec_skip2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "손실함수 구성 완료\n"
     ]
    }
   ],
   "source": [
    "optimizer=tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "#multi-class classification에 사용된다는 CategorialCrossentropy\n",
    "#여담이지만 docs에 Categorical_Crossentropy도 있었다.\n",
    "#CategoricalCrossentropy -> computes the crossentropy loss between the labels and predictions\n",
    "model_spec_skip2.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "             optimizer=optimizer,\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "print(\"손실함수 구성 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가중치 저장을 위한 콜백함수 설정 완료\n"
     ]
    }
   ],
   "source": [
    "#이전의 모델과 분리\n",
    "check_skip_path = os.getenv('HOME')+'/SUBMIT_MISSION_GIT/ex5_STT/skipPath/skip'\n",
    "\n",
    "check_skip_path\n",
    "\n",
    "spec_skip_callback = tf.keras.callbacks.ModelCheckpoint(check_skip_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 monitor='val_loss',\n",
    "                                                 mode='auto',\n",
    "                                                 save_best_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "print(\"가중치 저장을 위한 콜백함수 설정 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__아까 학습이 epoch=4 인 이후로 train loss와 validation loss가 떨어졌으므로  epoch를 5로 정해준다.__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1423/1423 [==============================] - ETA: 0s - loss: 0.8230 - accuracy: 0.7366\n",
      "Epoch 00001: val_loss improved from inf to 0.36091, saving model to /home/ssac23/SUBMIT_MISSION_GIT/ex5_STT/skipPath/skip\n",
      "1423/1423 [==============================] - 73s 51ms/step - loss: 0.8230 - accuracy: 0.7366 - val_loss: 0.3609 - val_accuracy: 0.8890\n",
      "Epoch 2/5\n",
      "1423/1423 [==============================] - ETA: 0s - loss: 0.2714 - accuracy: 0.9168\n",
      "Epoch 00002: val_loss improved from 0.36091 to 0.26613, saving model to /home/ssac23/SUBMIT_MISSION_GIT/ex5_STT/skipPath/skip\n",
      "1423/1423 [==============================] - 74s 52ms/step - loss: 0.2714 - accuracy: 0.9168 - val_loss: 0.2661 - val_accuracy: 0.9134\n",
      "Epoch 3/5\n",
      "1423/1423 [==============================] - ETA: 0s - loss: 0.1745 - accuracy: 0.9479\n",
      "Epoch 00003: val_loss improved from 0.26613 to 0.17612, saving model to /home/ssac23/SUBMIT_MISSION_GIT/ex5_STT/skipPath/skip\n",
      "1423/1423 [==============================] - 74s 52ms/step - loss: 0.1745 - accuracy: 0.9479 - val_loss: 0.1761 - val_accuracy: 0.9403\n",
      "Epoch 4/5\n",
      "1423/1423 [==============================] - ETA: 0s - loss: 0.1233 - accuracy: 0.9634\n",
      "Epoch 00004: val_loss improved from 0.17612 to 0.17037, saving model to /home/ssac23/SUBMIT_MISSION_GIT/ex5_STT/skipPath/skip\n",
      "1423/1423 [==============================] - 74s 52ms/step - loss: 0.1233 - accuracy: 0.9634 - val_loss: 0.1704 - val_accuracy: 0.9438\n",
      "Epoch 5/5\n",
      "1423/1423 [==============================] - ETA: 0s - loss: 0.0948 - accuracy: 0.9724\n",
      "Epoch 00005: val_loss improved from 0.17037 to 0.13888, saving model to /home/ssac23/SUBMIT_MISSION_GIT/ex5_STT/skipPath/skip\n",
      "1423/1423 [==============================] - 75s 53ms/step - loss: 0.0948 - accuracy: 0.9724 - val_loss: 0.1389 - val_accuracy: 0.9551\n",
      "모델 학습\n"
     ]
    }
   ],
   "source": [
    "#batch=32, epoch=5\n",
    "history_spec_skip2 = model_spec_skip2.fit(train_dataset, epochs=5,\n",
    "                    steps_per_epoch=len(train_spec) // batch_size,\n",
    "                    validation_data=test_dataset,\n",
    "                    validation_steps=len(test_spec) // batch_size,\n",
    "                    callbacks=[spec_skip_callback]\n",
    "                    )\n",
    "\n",
    "print(\"모델 학습\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이전 기록을 가져왔다.\n"
     ]
    }
   ],
   "source": [
    "#우리가 콜백 함수를 통해 저장한 weight를 가져와보도록 하자.\n",
    "model_spec_skip2.load_weights(check_skip_path)\n",
    "\n",
    "print(\"이전 기록을 가져왔다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 3s 17ms/step - loss: 0.1387 - accuracy: 0.9552\n",
      "테스트 데이터셋으로 평가해보자.\n",
      "\n",
      "loss value : 0.139\n",
      "\n",
      "acuuracy value : 95.5156\n"
     ]
    }
   ],
   "source": [
    "results = model_spec_skip2.evaluate(test_dataset)\n",
    "print(\"테스트 데이터셋으로 평가해보자.\")\n",
    "\n",
    "#로스\n",
    "print(\"\\nloss value : {:.3f}\".format(results[0]))\n",
    "\n",
    "#정확도\n",
    "print(\"\\nacuuracy value : {:.4f}\".format(results[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 좋은 결과였지만, 이전보다 좋은 정확도를 끌어내지는 못했다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ~한편으로는 너무 높은 정확도라서 과연 맞는 테스트였던걸까? 하는 생각이 들기도 한다.~     \n",
    "* 어떻게 개선해야 더 좋은 결과를 이끌어낼 수 있을까?      \n",
    "---\n",
    "__시도해 볼 만한 것들__       \n",
    "1. 정확도 평가를 바꿔보기 위해 다른 평가 set 써보고, 결과가 비슷하게 나오는지 보기\n",
    "2. 만약 1에서 정확도 평가가 비슷하거나 더 낫게 나왔다면, 모델을 좀 바꿔보기(더 간소한 레이어로)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
