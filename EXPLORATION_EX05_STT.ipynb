{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration 05_ STT        \n",
    "---\n",
    "## 이 노드의 루브릭      \n",
    "1. 음성데이터를 2차원 Spectogram으로 변환하여 데이터셋을 구성하였다.      \n",
    "    -> \"스펙토그램 시각화 및 train/test 데이터셋 구성이 정상 진행되었다.\"    \n",
    "    \n",
    "    \n",
    "2. 1, 2차원 데이터를 처리하는 음성인식 모델이 정상 작동한다.          \n",
    "    -> \"스펙토그램을 입력받은 모델이 학습 과정에서 안정적으로 수렴하며, evaluation/test 단계를 무리없이 진행 가능하다.      \n",
    "    \n",
    "    \n",
    "    \n",
    "3. 테스트셋 수행 결과 음성인식 모델의 Accuracy가 일정 수준에 도달하였다.     \n",
    "    -> \"평가 결과 75% 이상의 정확도를 달성하는 모델이 하나 이상 존재한다.\"    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 목차       \n",
    "\n",
    "1. 데이터 처리와 분류    \n",
    "  - 라벨 데이터 처리하기\n",
    "  - sklearn의 train_test_split 함수를 이용하여 train, test 분리   \n",
    "2. 학습을 위한 하이퍼파라미터 설정     \n",
    "3. 데이터셋 구성        \n",
    "  - tf.data.Dataset을 이용       \n",
    "  - from_tensor_slices에 return 받길 원하는 데이터를 튜플 형태로 받음   \n",
    "  - map과 batch를 사용한 데이터 전처리.\n",
    "  - 메모리 비우기 수행하기    \n",
    "  \n",
    "  > del speech_data\n",
    "  > del spec_data\n",
    "  \n",
    "4. 2차원 Spectogram 데이터를 처리하는 모델 구성     \n",
    "  - 2차원 Spectogram 데이터의 시간축 방향으로 Conv1D/Conv2D 레이어를 적용가능    \n",
    "  - batchnorm, dropout, dense layer 를 이용    \n",
    "  - 12개의 단어 class를 구분하는 loss를 사용하고, Adam optimizer 사용   \n",
    "  - 모델 가중치를 저장하는 checkpoint callback 함수 추가     \n",
    "  \n",
    "5. 학습 내용 그래프 출력\n",
    "  - loss, accuracy를 그래프로 표현     \n",
    "  \n",
    "6. Test dataset을 이용한 모델의 성능 평가   \n",
    "  - 저장한 weight 불러오기    \n",
    "  - 모델의 예측값과 정답값이 얼마나 맞는지 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터 처리와 분류      \n",
    "##### 데이터 가져오기       \n",
    "* 기존에는 Waveform 데이터로 입력받아, Text라벨을 출력하는 모델을 만들었다.    \n",
    "* 이제 이 데이터를 Spectogram으로 입력받아, 동일 역할을 수행하는 모델을 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터를 가져왔다!\n",
      "wav 상태 그대로의 데이터 셰이프 : (50620, 8000)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "data_path = os.getenv(\"HOME\")+'/SUBMIT_MISSION_GIT/ex5_STT/data/speech_wav_8000.npz'\n",
    "speech_data = np.load(data_path)\n",
    "\n",
    "print(\"데이터를 가져왔다!\")\n",
    "print(\"wav 상태 그대로의 데이터 셰이프 :\", speech_data[\"wav_vals\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 내겐 너무 어려웠던 데이터 형변환         \n",
    "* 사실, speech_data -> spectogram data로 형변환하는 과정이 너무 어려웠다.   \n",
    "* 하나하나씩 차근히 분해해보기로 했다.         \n",
    "---\n",
    "1. 일단, speech_data를 이루고 있는 저 npz 확장자는 대체 무엇인지     \n",
    "* npz 파일 포맷은 여러 개의 리스트를 한번에 저장하기 위한 포맷이다.     \n",
    "* 그렇군.      \n",
    "---\n",
    "* 그럼, 얘 안에 들어있는 데이터들은 뭘까?      \n",
    "* 위에서 speech_data를 살펴보았을 때, 데이터는     \n",
    "* speech_data[\"wav_vals\"]와 speech_data[\"label_vals\"]가 있었다.    \n",
    "* wav_vals는 음성 데이터, label_vals는 음성의 뜻을 의미하는 라벨 데이터이다.  \n",
    "* 프린트해서 다시 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "음성 데이터 shape :  (50620, 8000)\n",
      "\n",
      "어떻게 생겼나? [-1.27418665e-04 -1.12644804e-04 -1.86756923e-04 ... -1.62762426e-05\n",
      " -4.93293861e-04 -3.55132594e-04]\n",
      "\n",
      "라벨 데이터 shape :  (50620, 1)\n",
      "\n",
      "어떻게 생겼나? ['down']\n"
     ]
    }
   ],
   "source": [
    "#wav_vals와 label_vals 인쇄\n",
    "print(\"음성 데이터 shape : \" ,speech_data[\"wav_vals\"].shape)\n",
    "print(\"\\n어떻게 생겼나?\" , speech_data[\"wav_vals\"][0])\n",
    "\n",
    "print(\"\\n라벨 데이터 shape : \" ,speech_data[\"label_vals\"].shape)\n",
    "print(\"\\n어떻게 생겼나?\" , speech_data[\"label_vals\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 인쇄해봤더니, 위와 같았다.     \n",
    "* 음성데이터는 (음성개수:50620개, 샘플링 레이트 8000)       \n",
    "* 라벨데이터는 (라벨개수:50620개, 라벨 값이 들어간 1개)   \n",
    "* 의 모양으로 생긴 것을 확인할 수 있다.       \n",
    "---\n",
    "__그럼 우리는 이제 spectogram 데이터가 어떤 모양인지 알아야 한다!__   \n",
    "\n",
    "![데이터 변환](./PostingPic/data.png)         \n",
    "\n",
    "* 사진을 보면, 노드에서 wav데이터를 spectogram으로 변환할 때     \n",
    "* Waveform shape(8000,) 스펙토그램(130,126)으로 바뀐 것을 알 수 있다.    \n",
    "* 그럼 일렬로 된 8000개의 샘플링 데이터를 -> 음성 1개당 (130,126)의 데이터로 변환시켜야 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.0723902e-03 5.2032182e-03 3.4693219e-03 ... 1.8922662e-02\n",
      "  3.3809434e-04 1.0142580e-02]\n",
      " [6.5486785e-03 3.2852096e-03 2.2495915e-03 ... 2.5527487e-02\n",
      "  1.6525777e-02 3.2326202e-03]\n",
      " [2.4226354e-03 3.5080472e-03 2.4726372e-03 ... 2.7952474e-02\n",
      "  2.6693283e-02 1.7628349e-02]\n",
      " ...\n",
      " [5.8292970e-04 2.9035914e-04 1.4131786e-05 ... 6.0245253e-05\n",
      "  3.1307511e-04 5.0933618e-04]\n",
      " [5.2434229e-04 2.5860392e-04 1.2995474e-05 ... 2.1275569e-05\n",
      "  2.2292971e-04 4.7651122e-04]\n",
      " [5.1448052e-04 2.5908535e-04 1.6500426e-06 ... 5.2643327e-06\n",
      "  2.3299157e-04 4.3895244e-04]]\n"
     ]
    }
   ],
   "source": [
    "#wav 데이터를 spectogram으로 변환한다.\n",
    "import librosa\n",
    "\n",
    "#wav 데이터를 spectogram 데이터로 바꾸는 매직\n",
    "#fft_size는 스펙토그램 사이즈를 맞추기 위해 258로 고정   \n",
    "def wav2spec(wav, fft_size=258):\n",
    "    D = np.abs(librosa.stft(wav, n_fft=fft_size))\n",
    "    return D\n",
    "\n",
    "#변환한 data를 담아줄 리스트\n",
    "specData =[]\n",
    "\n",
    "for wav_data in speech_data[\"wav_vals\"]:\n",
    "    specData.append(wav2spec(wav_data))\n",
    "    \n",
    "print(specData[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 리스트로 만들었으니, 이 리스트의 형태를 연산할 수 있게 np.array로 변환해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specData = np.array(specData)\n",
    "\n",
    "print(\"Spectrogram shape : \",specData.shape)\n",
    "print(\"1개 데이터의 모양 : \", specData[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 50620개의 데이터를 1데이터 당 (130,126) 사이즈로 변환했다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터 처리하기 - 1) 라벨 데이터 처리하기          \n",
    "\n",
    "* 그럼 이제 라벨 데이터도 같은 모양을 갖도록 처리해보자!     \n",
    "* 현재의 라벨 데이터 모양을 출력해본다.       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50620, 1)\n"
     ]
    }
   ],
   "source": [
    "print(speech_data[\"label_vals\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 라벨 데이터의 종류들을 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['down' 'go' 'left' 'no' 'off' 'on' 'right' 'silence' 'stop' 'unknown'\n",
      " 'up' 'yes']\n"
     ]
    }
   ],
   "source": [
    "label_list = np.unique(speech_data[\"label_vals\"])\n",
    "print(label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 이 12개의 데이터들을, 학습에 사용하기 위해 딕셔너리 형태로 바꿔준다.    \n",
    "* 단, 현재 0:down, 1:go.... 로 되어있는 리스트를 거꾸로 down:0 이 되도록 바꿔주어야 컴퓨터가 처리 가능하다.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indexed labels :  {'down': 0, 'go': 1, 'left': 2, 'no': 3, 'off': 4, 'on': 5, 'right': 6, 'silence': 7, 'stop': 8, 'unknown': 9, 'up': 10, 'yes': 11}\n"
     ]
    }
   ],
   "source": [
    "label_data_dict = dict() \n",
    "\n",
    "for i, l in enumerate(label_list):\n",
    "    label_data_dict[l] = i\n",
    "    \n",
    "label_list = label_data_dict\n",
    "\n",
    "print(\"indexed labels : \" , label_data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 12개의 라벨이 모두 __라벨(str값):인덱스  의 형태로 변환__ 된 것을 확인할 수 있다.     \n",
    "* 여기서 다시 라벨을 연산이 가능한 np.array 형태로 바꿔준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전부 다 변환됐는가? :  50620\n",
      "(50620,)\n",
      "몇 개만 출력해보자  0 1\n"
     ]
    }
   ],
   "source": [
    "temp = []\n",
    "\n",
    "for value in speech_data[\"label_vals\"]:\n",
    "    temp.append(label_list[value[0]])\n",
    "\n",
    "print(\"전부 다 변환됐는가? : \" , len(temp))\n",
    "label_data = np.array(temp)\n",
    "\n",
    "print(label_data.shape)\n",
    "print(\"몇 개만 출력해보자 \" ,  label_data[9] , label_data[2850])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 확인해보니, 50620개의 데이터가 모두 label_data 형태로 변환되었음을 알 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.데이터 처리하기 - 2. 학습 데이터, 테스트 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'specData' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-300c3aef4b52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# 학습데이터:테스트데이터 = 9:1 로 해 보았다 ㅎㅎ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrain_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspecData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"학습 데이터 수\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'specData' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#차원 알려주기\n",
    "sp_s=130\n",
    "sp_p=126\n",
    "\n",
    "# 학습데이터:테스트데이터 = 9:1 로 해 보았다 ㅎㅎ\n",
    "train_spec, test_spec, train_label, test_label = train_test_split(specData, label_data, test_size=0.1, shuffle=True)\n",
    "print(\"학습 데이터 수\", len(train_spec))\n",
    "\n",
    "train_spec = train_spec.reshape([-1, sp_s, sp_p,1])\n",
    "test_spec = test_spec.reshape([-1, sp_s, sp_p,1])\n",
    "\n",
    "#나눠진 데이터 모습을 확인해보자.\n",
    "print(\"train_spec : \", train_spec.shape)\n",
    "print(\"train_label :\" , train_label.shape)\n",
    "print(\"test_spec : \", test_spec.shape)\n",
    "print(\"test_label :\", test_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 학습을 위한 하이퍼파라미터 설정          \n",
    "\n",
    "* 혹시 모르는 마음에, 기본적인 설정은 노드와 동일하게 진행해주었다.      \n",
    "* 추후 성능에 따라 하이퍼파라미터를 조정해주도록 한다.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ssac23/SUBMIT_MISSION_GIT/ex5_STT/model/wav'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "max_epoch = 10\n",
    "\n",
    "#중간중간 저장해줄 체크포인트 생성\n",
    "check_path = os.getenv('HOME')+'/SUBMIT_MISSION_GIT/ex5_STT/model/wav'\n",
    "\n",
    "check_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 데이터셋 구성 - 1) 데이터셋 구성     \n",
    "\n",
    "---\n",
    "__요건__       \n",
    "* tf.data.Dataset을 이용        \n",
    "* from_tensor_slices에 return 받길 원하는 데이터를 튜플 형태로 받음     \n",
    "* map과 batch를 사용한 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot_label\n"
     ]
    }
   ],
   "source": [
    "#정답 라벨 말고는 다 죽이는 one_hot_label\n",
    "def one_hot_label(spec,label):\n",
    "    \n",
    "    #depth=12는 최종 결과값이 12개 나온다는 의미(물론 뒤에 1차원이 더 붙는다.)\n",
    "    #우리 라벨 데이터는 12개이므로 depth=12임!\n",
    "    label = tf.one_hot(label, depth=12)\n",
    "    return spec, label\n",
    "\n",
    "print(\"one_hot_label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((None, 130, 126), (None, 12)), types: (tf.float32, tf.float32)>\n",
      "<BatchDataset shapes: ((None, 130, 126), (None, 12)), types: (tf.float32, tf.float32)>\n",
      "데이터 처리 완료\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_spec, train_label))\n",
    "train_dataset = train_dataset.map(one_hot_label)\n",
    "train_dataset = train_dataset.repeat().batch(batch_size=batch_size)\n",
    "print(train_dataset)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_spec, test_label))\n",
    "test_dataset = test_dataset.map(one_hot_label)\n",
    "test_dataset = test_dataset.batch(batch_size=batch_size)\n",
    "print(test_dataset)\n",
    "\n",
    "print(\"데이터 처리 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__메모리 비우기 수행하기__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del speech_data\n",
    "del specData\n",
    "print(\"비우기 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 2차원 Spectogram 데이터를 처리하는 모델 구성      \n",
    "---   \n",
    "__요건__     \n",
    "* 2차원 spectogram 데이터의 시간축 방향으로 Conv1D, Conv2D 레이어를 적용 가능   \n",
    "* batchnorm, dropout, dense layer를 이용    \n",
    "* 12개의 단어 class를 구분하는 loss를 사용하고, Adam optimizer 사용     \n",
    "* 모델 가중치를 저장하는 checkpoint callback 함수 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer conv1d is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: [None, 45558, 130, 126]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-ffc8e48ad1ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPool1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0;31m# are casted, not before.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m         input_spec.assert_input_compatibility(self.input_spec, inputs,\n\u001b[0;32m--> 886\u001b[0;31m                                               self.name)\n\u001b[0m\u001b[1;32m    887\u001b[0m         if (any(isinstance(x, ragged_tensor.RaggedTensor) for x in input_list)\n\u001b[1;32m    888\u001b[0m             and self._supports_ragged_inputs is False):  # pylint: disable=g-bool-id-comparison\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    178\u001b[0m                          \u001b[0;34m'expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                          \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. Full shape received: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                          str(x.shape.as_list()))\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer conv1d is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: [None, 45558, 130, 126]"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "#spec_data의 형태를 알려준다.\n",
    "input_tensor = layers.Input(shape=train_spec.shape)\n",
    "\n",
    "x = layers.Conv1D(32, 9, padding='same', activation='relu')(input_tensor)\n",
    "x = layers.Conv1D(32, 9, padding='same', activation='relu')(x)\n",
    "x = layers.MaxPool1D()(x)\n",
    "\n",
    "x = layers.Conv1D(64, 9, padding='same', activation='relu')(x)\n",
    "x = layers.Conv1D(64, 9, padding='same', activation='relu')(x)\n",
    "x = layers.MaxPool1D()(x)\n",
    "\n",
    "x = layers.Conv1D(128, 9, padding='same', activation='relu')(x)\n",
    "x = layers.Conv1D(128, 9, padding='same', activation='relu')(x)\n",
    "x = layers.Conv1D(128, 9, padding='same', activation='relu')(x)\n",
    "x = layers.MaxPool1D()(x)\n",
    "\n",
    "x = layers.Conv1D(256, 9, padding='same', activation='relu')(x)\n",
    "x = layers.Conv1D(256, 9, padding='same', activation='relu')(x)\n",
    "x = layers.Conv1D(256, 9, padding='same', activation='relu')(x)\n",
    "x = layers.MaxPool1D()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(256)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "\n",
    "output_tensor = layers.Dense(12)(x)\n",
    "\n",
    "model_spec = tf.keras.Model(input_tensor, output_tensor)\n",
    "\n",
    "model_spec.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
